{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "import keras\n",
    "import keras.utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential #Initialise our neural network model as a sequential network\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.layers import Conv2D #Convolution operation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Activation #Applies activation function\n",
    "from keras.layers import Dropout #Prevents overfitting by randomly converting few outputs to zero\n",
    "from keras.layers import MaxPooling2D # Maxpooling function\n",
    "from keras.layers import Flatten # Converting 2D arrays into a 1D linear vector\n",
    "from keras.layers import Dense # Regular fully connected neural network\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "  \n",
    "  #classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprsie', 'Neutral']  #We will be dealing with seven different types of emotions.\n",
    "\n",
    "  data = []\n",
    "  test_data = []\n",
    "  test_labels = []\n",
    "  labels =[]\n",
    "\n",
    "  with open(dataset_path, 'r') as file:\n",
    "      for line_no, line in enumerate(file.readlines()):\n",
    "          if 0 < line_no <= 35887:\n",
    "            curr_class, line, set_type = line.split(',')\n",
    "            image_data = np.asarray([int(x) for x in line.split()]).reshape(48, 48)#Creating a list out of the string then converting it into a 2-Dimensional numpy array.\n",
    "            image_data =image_data.astype(np.uint8)/255.0\n",
    "            \n",
    "            if (set_type.strip() == 'PrivateTest'):\n",
    "              \n",
    "              test_data.append(image_data)\n",
    "              test_labels.append(curr_class)\n",
    "            else:\n",
    "              data.append(image_data)\n",
    "              labels.append(curr_class)\n",
    "      \n",
    "      test_data = np.expand_dims(test_data, -1)\n",
    "      test_labels = to_categorical(test_labels, num_classes = 7)\n",
    "      data = np.expand_dims(data, -1)   \n",
    "      labels = to_categorical(labels, num_classes = 7)\n",
    "    \n",
    "      return np.array(data), np.array(labels), np.array(test_data), np.array(test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/Emotion Recognition/Data/fer2013.csv\"\n",
    "train_data, train_labels, test_data, test_labels = load_data(dataset_path)\n",
    "#train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = test_size,random_state = seed)\n",
    "\n",
    "print(\"Number of images in Training set:\", len(train_data))\n",
    "print(\"Number of images in Test set:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Sequential model - \"Initial_Model\"  without regulrization\n",
    "#######HYPERPARAMATERS###########\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "#################################\n",
    "\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1), kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "adam = tensorflow.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "print(model.summary())\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
    "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=6, mode='auto')\n",
    "checkpointer = ModelCheckpoint('/content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(\n",
    "          train_data,\n",
    "          train_labels,\n",
    "          epochs = epochs,\n",
    "          batch_size = batch_size,\n",
    "          validation_split = 0.2,\n",
    "          shuffle = True,\n",
    "          callbacks=[lr_reducer, checkpointer, early_stopper]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
